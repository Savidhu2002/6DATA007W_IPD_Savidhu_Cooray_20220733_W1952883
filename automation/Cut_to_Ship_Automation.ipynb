{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f0bd8-0803-4222-8066-50187e54f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Cut to Ship Report Automation\n",
    "# Robust to column name variations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalize column names: remove weird whitespace, trim, keep as strings.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)  # collapse whitespace/newlines/tabs\n",
    "        .str.strip()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def find_col(df: pd.DataFrame, text: str, prefer_exact: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Find a column that matches text.\n",
    "    - If prefer_exact, first try exact match (case-insensitive).\n",
    "    - Otherwise find first column containing the text (case-insensitive).\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    if prefer_exact:\n",
    "        for c in cols:\n",
    "            if c.strip().lower() == text.strip().lower():\n",
    "                return c\n",
    "\n",
    "    matches = [c for c in cols if text.lower() in c.lower()]\n",
    "    if not matches:\n",
    "        raise KeyError(\n",
    "            f\"Could not find a column containing '{text}'. Available columns:\\n{cols}\"\n",
    "        )\n",
    "    return matches[0]\n",
    "\n",
    "def ensure_datetime(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert series to datetime safely.\"\"\"\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def safe_str(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert series to string, preserving NaN as empty string for concatenations.\"\"\"\n",
    "    return s.fillna(\"\").astype(str)\n",
    "\n",
    "# -----------------------------\n",
    "# Defining the paths for the datasets\n",
    "# -----------------------------\n",
    "D1_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Style Closure -Week 43.xlsx\"\n",
    "D2_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Garment Sales Order-Week 43.xlsx\"\n",
    "D3_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Order Book -Week 43.xlsx\"\n",
    "D4_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Transaction Summary -Week 43.xlsx\"\n",
    "D5_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Export Summary -Week 43.xlsx\"\n",
    "D6_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Last Shipment- Week 43.xlsx\"\n",
    "D7_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Master sheet - customer name.xlsx\"\n",
    "\n",
    "# -----------------------------\n",
    "# Loading the datasets\n",
    "# -----------------------------\n",
    "D1 = pd.read_excel(D1_path, sheet_name=\"Sheet1\")\n",
    "D2 = pd.read_excel(D2_path, sheet_name=\"Sheet1\")\n",
    "D3 = pd.read_excel(D3_path, sheet_name=\"Sheet1\")\n",
    "D4 = pd.read_excel(D4_path, sheet_name=\"Sheet1\")\n",
    "D5 = pd.read_excel(D5_path, sheet_name=\"Sheet1\")\n",
    "D6 = pd.read_excel(D6_path, sheet_name=\"Sheet1\")\n",
    "D7 = pd.read_excel(D7_path, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Clean column names\n",
    "D1 = clean_cols(D1)\n",
    "D2 = clean_cols(D2)\n",
    "D3 = clean_cols(D3)\n",
    "D4 = clean_cols(D4)\n",
    "D5 = clean_cols(D5)\n",
    "D6 = clean_cols(D6)\n",
    "D7 = clean_cols(D7)\n",
    "\n",
    "# -----------------------------\n",
    "# Resolving column names\n",
    "# -----------------------------\n",
    "# D2 filter columns\n",
    "D2_gen = find_col(D2, \"General sales order\")\n",
    "D2_sample = find_col(D2, \"Sample sales orders\")\n",
    "D2_salesman = find_col(D2, \"Salesman order\")\n",
    "D2_sales_order = find_col(D2, \"Sales order\")  # could be Sales order, Sales order.1, etc.\n",
    "\n",
    "# D1 columns\n",
    "D1_sales_order = find_col(D1, \"Sales order\")\n",
    "D1_customer = find_col(D1, \"Customer account\")\n",
    "D1_style_closed = find_col(D1, \"Style closed date\")\n",
    "\n",
    "# D7 columns\n",
    "D7_customer = find_col(D7, \"Customer\")\n",
    "D7_calling = find_col(D7, \"Calling Name\")\n",
    "\n",
    "# D3 columns\n",
    "D3_sales_order = find_col(D3, \"Sales order\")\n",
    "D3_division = find_col(D3, \"Division\")\n",
    "D3_season = find_col(D3, \"Season\")\n",
    "D3_style_no = find_col(D3, \"Style number\")\n",
    "D3_item_type = find_col(D3, \"Garment item type\")\n",
    "D3_site = find_col(D3, \"Site\")\n",
    "D3_set_garment = find_col(D3, \"Set garment\")\n",
    "D3_qty = find_col(D3, \"Quantity\")\n",
    "\n",
    "# D4 columns\n",
    "D4_sales_order = find_col(D4, \"Sales order\")\n",
    "D4_unit = find_col(D4, \"Unit\")\n",
    "D4_qty = find_col(D4, \"Qty\")\n",
    "\n",
    "# D5 columns\n",
    "D5_sales_order = find_col(D5, \"Sales order\")\n",
    "D5_site = find_col(D5, \"Site\")\n",
    "D5_invoice = find_col(D5, \"Customer invoice\")\n",
    "D5_date = find_col(D5, \"Date\")\n",
    "D5_invoice_qty = find_col(D5, \"Invoice qty\")\n",
    "D5_fob = find_col(D5, \"FOB\")\n",
    "\n",
    "# D6 columns\n",
    "D6_sales_order = find_col(D6, \"Sales order\")\n",
    "D6_approved_date = find_col(D6, \"Approved date\")\n",
    "\n",
    "# Ensure datetime fields\n",
    "D1[D1_style_closed] = ensure_datetime(D1[D1_style_closed])\n",
    "D6[D6_approved_date] = ensure_datetime(D6[D6_approved_date])\n",
    "D5[D5_date] = ensure_datetime(D5[D5_date])\n",
    "\n",
    "# -----------------------------\n",
    "# Filtering D2 for Sales orders where all three columns are \"No\"\n",
    "# -----------------------------\n",
    "filtered_D2 = D2[\n",
    "    (D2[D2_gen] == \"No\") &\n",
    "    (D2[D2_sample] == \"No\") &\n",
    "    (D2[D2_salesman] == \"No\")\n",
    "][[D2_sales_order]].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Filtering D1 to keep only Sales orders matching filtered D2 (semi_join)\n",
    "# -----------------------------\n",
    "filtered_D1 = D1[D1[D1_sales_order].isin(filtered_D2[D2_sales_order])].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize result with filtered Sales orders\n",
    "# -----------------------------\n",
    "result = filtered_D1[[D1_sales_order]].copy()\n",
    "result = result.rename(columns={D1_sales_order: \"Sales_order\"})\n",
    "\n",
    "# -----------------------------\n",
    "# Add Customer from D1\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D1[[D1_sales_order, D1_customer]].rename(columns={D1_sales_order: \"Sales_order\", D1_customer: \"Customer\"}),\n",
    "    on=\"Sales_order\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Add Calling Name from D7 based on Customer\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D7[[D7_customer, D7_calling]].rename(columns={D7_customer: \"Customer\", D7_calling: \"Calling_Name\"}),\n",
    "    on=\"Customer\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Add other columns from D3 by matching Sales order\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D3[[D3_sales_order, D3_division, D3_season, D3_style_no, D3_item_type, D3_site, D3_set_garment]].rename(\n",
    "        columns={\n",
    "            D3_sales_order: \"Sales_order\",\n",
    "            D3_division: \"Division\",\n",
    "            D3_season: \"Season\",\n",
    "            D3_style_no: \"Style_number\",\n",
    "            D3_item_type: \"Garment_item_type\",\n",
    "            D3_site: \"Unit\",\n",
    "            D3_set_garment: \"Set_garment\",\n",
    "        }\n",
    "    ),\n",
    "    on=\"Sales_order\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Add \"Last Shipped\" from D6 (max Approved date per Sales order)\n",
    "# -----------------------------\n",
    "last_shipped = (\n",
    "    D6.groupby(D6_sales_order, as_index=False)[D6_approved_date]\n",
    "    .max()\n",
    "    .rename(columns={D6_sales_order: \"Sales_order\", D6_approved_date: \"Last_Shipped\"})\n",
    ")\n",
    "\n",
    "result = result.merge(last_shipped, on=\"Sales_order\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Add \"Style closed date\" from D1\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D1[[D1_sales_order, D1_style_closed]].rename(columns={D1_sales_order: \"Sales_order\", D1_style_closed: \"Style_closed_date\"}),\n",
    "    on=\"Sales_order\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Add Month and Week\n",
    "# -----------------------------\n",
    "# Month abbreviations like Jan, Feb, ...\n",
    "result[\"Month\"] = result[\"Style_closed_date\"].dt.month_name().str[:3]\n",
    "\n",
    "# ISO week number, formatted Week 02, Week 43, ...\n",
    "iso_week = result[\"Style_closed_date\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "result[\"Week\"] = iso_week.apply(lambda x: f\"Week {int(x):02d}\" if pd.notna(x) else np.nan)\n",
    "\n",
    "# -----------------------------\n",
    "# Add Operation based on Sales order prefix\n",
    "# -----------------------------\n",
    "so_str = safe_str(result[\"Sales_order\"])\n",
    "result[\"Operation\"] = np.where(\n",
    "    so_str.str.startswith(\"N\"), \"Knit Operation\",\n",
    "    np.where(so_str.str.startswith(\"W\"), \"Woven Operation\", \"Other Operation\")\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Remove Sales orders with \"Oritapparels\" and \"Southasiatextiles\" in Customer column (case-insensitive)\n",
    "# -----------------------------\n",
    "result = result[~result[\"Customer\"].astype(str).str.lower().str.contains(\"oritapparels|southasiatextiles\", regex=True, na=False)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Code column combining Sales order and Unit\n",
    "# -----------------------------\n",
    "result[\"Code\"] = safe_str(result[\"Sales_order\"]) + safe_str(result[\"Unit\"])\n",
    "\n",
    "# Create Code columns in D3, D4, D5\n",
    "D3[\"Code\"] = safe_str(D3[D3_sales_order]) + safe_str(D3[D3_site])\n",
    "D4[\"Code\"] = (safe_str(D4[D4_sales_order]) + safe_str(D4[D4_unit])).str.upper()\n",
    "D5[\"Code\"] = safe_str(D5[D5_sales_order]) + safe_str(D5[D5_site])\n",
    "\n",
    "# -----------------------------\n",
    "# Summarize quantities by Code\n",
    "# -----------------------------\n",
    "# Order Qty: exclude Site containing HIKH-SAMP|HKSAM\n",
    "order_qty = (\n",
    "    D3[~D3[D3_site].astype(str).str.contains(\"HIKH-SAMP|HKSAM\", regex=True, na=False)]\n",
    "    .groupby(\"Code\", as_index=False)[D3_qty]\n",
    "    .sum()\n",
    "    .rename(columns={D3_qty: \"Order_Qty\"})\n",
    ")\n",
    "\n",
    "# Cut Qty: sum Qty by Code (Code already upper in D4)\n",
    "cut_qty = (\n",
    "    D4.groupby(\"Code\", as_index=False)[D4_qty]\n",
    "    .sum()\n",
    "    .rename(columns={D4_qty: \"Cut_Qty\"})\n",
    ")\n",
    "\n",
    "# Ship Qty: exclude invoices starting with scl|rtn|dummy|sms|ss (case-insensitive),\n",
    "# then distinct by (Customer invoice, Date, Invoice qty) and sum Invoice qty by Code\n",
    "ship_qty = (\n",
    "    D5[\n",
    "        ~D5[D5_invoice].astype(str).str.lower().str.match(r\"^(scl|rtn|dummy|sms|ss)\", na=False)\n",
    "    ]\n",
    "    .drop_duplicates(subset=[D5_invoice, D5_date, D5_invoice_qty])\n",
    "    .groupby(\"Code\", as_index=False)[D5_invoice_qty]\n",
    "    .sum()\n",
    "    .rename(columns={D5_invoice_qty: \"Ship_Qty\"})\n",
    ")\n",
    "\n",
    "# Merge quantities into result\n",
    "result = result.merge(order_qty, on=\"Code\", how=\"left\")\n",
    "result = result.merge(cut_qty, on=\"Code\", how=\"left\")\n",
    "result = result.merge(ship_qty, on=\"Code\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# SO Type\n",
    "# -----------------------------\n",
    "result[\"SO_Type\"] = \"Bulk\"\n",
    "\n",
    "# -----------------------------\n",
    "# Pcs based on Set_garment and Style_number\n",
    "# R logic:\n",
    "# if Single -> 1\n",
    "# else if contains Pack -> extract digits from Style_number before PK or P\n",
    "# limit Pcs > 10 to NA\n",
    "# adjust Cut_Qty = Cut_Qty / Pcs when Pcs not NA\n",
    "# -----------------------------\n",
    "set_g = result[\"Set_garment\"].astype(str)\n",
    "style_num = result[\"Style_number\"].astype(str)\n",
    "\n",
    "pcs = np.where(\n",
    "    set_g.eq(\"Single\"), 1,\n",
    "    np.where(\n",
    "        set_g.str.contains(\"Pack\", na=False),\n",
    "        pd.to_numeric(style_num.str.extract(r\"(\\d+)(?=PK|P)\")[0], errors=\"coerce\"),\n",
    "        np.nan\n",
    "    )\n",
    ")\n",
    "\n",
    "result[\"Pcs\"] = pcs.astype(float)\n",
    "result.loc[result[\"Pcs\"] > 10, \"Pcs\"] = np.nan\n",
    "\n",
    "# Adjust Cut Qty based on Pcs\n",
    "result[\"Cut_Qty\"] = pd.to_numeric(result[\"Cut_Qty\"], errors=\"coerce\")\n",
    "result.loc[result[\"Pcs\"].notna(), \"Cut_Qty\"] = result.loc[result[\"Pcs\"].notna(), \"Cut_Qty\"] / result.loc[result[\"Pcs\"].notna(), \"Pcs\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Remove duplicates in Code (keep first)\n",
    "# -----------------------------\n",
    "result = result.drop_duplicates(subset=[\"Code\"], keep=\"first\").copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Ratios (no rounding)\n",
    "# -----------------------------\n",
    "result[\"Cut/Ship\"] = result[\"Ship_Qty\"] / result[\"Cut_Qty\"]\n",
    "result[\"Order/Ship\"] = result[\"Ship_Qty\"] / result[\"Order_Qty\"]\n",
    "result[\"Order/Cut\"] = result[\"Cut_Qty\"] / result[\"Order_Qty\"]\n",
    "\n",
    "# -----------------------------\n",
    "# FOB calculation from D5: sum(FOB * Invoice qty) by Code\n",
    "# -----------------------------\n",
    "D5_fob_total = pd.to_numeric(D5[D5_fob], errors=\"coerce\") * pd.to_numeric(D5[D5_invoice_qty], errors=\"coerce\")\n",
    "fob_data = (\n",
    "    D5.assign(FOB_Total=D5_fob_total)\n",
    "    .groupby(\"Code\", as_index=False)[\"FOB_Total\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"FOB_Total\": \"FOB\"})\n",
    ")\n",
    "\n",
    "result = result.merge(fob_data, on=\"Code\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final column selection and ordering (matching your R output)\n",
    "# -----------------------------\n",
    "result_out = result.rename(columns={\n",
    "    \"Sales_order\": \"Sales order\",\n",
    "    \"Calling_Name\": \"Calling Name\",\n",
    "    \"Division\": \"Div\",\n",
    "    \"Style_number\": \"Style number\",\n",
    "    \"Garment_item_type\": \"Garment item type\",\n",
    "    \"Last_Shipped\": \"Last Shipped\",\n",
    "    \"Style_closed_date\": \"Style closed date\",\n",
    "    \"Order_Qty\": \"Order Qty\",\n",
    "    \"Cut_Qty\": \"Cut Qty\",\n",
    "    \"Ship_Qty\": \"Ship Qty\",\n",
    "    \"SO_Type\": \"SO Type\",\n",
    "    \"Set_garment\": \"Set garment\",\n",
    "})\n",
    "\n",
    "# Filter for Style closed date in 2024\n",
    "result_out[\"Style closed date\"] = ensure_datetime(result_out[\"Style closed date\"])\n",
    "result_out = result_out[result_out[\"Style closed date\"].dt.year == 2024].copy()\n",
    "\n",
    "# Replace missing Cut Qty with Ship Qty if available\n",
    "result_out[\"Cut Qty\"] = pd.to_numeric(result_out[\"Cut Qty\"], errors=\"coerce\")\n",
    "result_out[\"Ship Qty\"] = pd.to_numeric(result_out[\"Ship Qty\"], errors=\"coerce\")\n",
    "result_out.loc[result_out[\"Cut Qty\"].isna() & result_out[\"Ship Qty\"].notna(), \"Cut Qty\"] = result_out.loc[\n",
    "    result_out[\"Cut Qty\"].isna() & result_out[\"Ship Qty\"].notna(), \"Ship Qty\"\n",
    "]\n",
    "\n",
    "# Filter out Unit contains Corporate or Sample\n",
    "result_out[\"Unit\"] = result_out[\"Unit\"].astype(str)\n",
    "result_out = result_out[~result_out[\"Unit\"].str.contains(\"Corporate|Sample\", regex=True, na=False)].copy()\n",
    "\n",
    "# Keep your exact output column order (including FOB after Code in your R, but you selected Code then FOB at end)\n",
    "# Your R final select order ends with: Code, FOB\n",
    "final_cols = [\n",
    "    \"Sales order\",\n",
    "    \"Customer\",\n",
    "    \"Calling Name\",\n",
    "    \"Div\",\n",
    "    \"Season\",\n",
    "    \"Style number\",\n",
    "    \"Garment item type\",\n",
    "    \"Unit\",\n",
    "    \"Last Shipped\",\n",
    "    \"Style closed date\",\n",
    "    \"Month\",\n",
    "    \"Order Qty\",\n",
    "    \"Cut Qty\",\n",
    "    \"Ship Qty\",\n",
    "    \"Cut/Ship\",\n",
    "    \"Order/Ship\",\n",
    "    \"Order/Cut\",\n",
    "    \"SO Type\",\n",
    "    \"Week\",\n",
    "    \"Operation\",\n",
    "    \"Set garment\",\n",
    "    \"Pcs\",\n",
    "    \"Code\",\n",
    "    \"FOB\",\n",
    "]\n",
    "\n",
    "# Some columns might not exist if source files miss them, so select safely\n",
    "final_cols_existing = [c for c in final_cols if c in result_out.columns]\n",
    "result_out = result_out[final_cols_existing].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Write output\n",
    "# -----------------------------\n",
    "output_path = (\n",
    "    r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\"\n",
    "    r\"\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\"\n",
    "    r\"\\Cut_to_Ship_Week_43_R2.xlsx\"\n",
    ")\n",
    "\n",
    "result_out.to_excel(output_path, index=False)\n",
    "print(\"Saved:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
