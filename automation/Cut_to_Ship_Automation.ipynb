{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487f0bd8-0803-4222-8066-50187e54f912",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:\\\\Savidhu_OneDrive\\\\OneDrive - Hirdaramani Group\\\\Projects\\\\Cut to Ship Prediction Model\\\\Cut to Ship Report Automation\\\\Cut_to_Ship_Week_43_Test.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 403\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Writing the final Cut to Ship report output to Excel\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[0;32m    397\u001b[0m output_path \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSavidhu_OneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Hirdaramani Group\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCut to Ship Prediction Model\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCut to Ship Report Automation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCut_to_Ship_Week_43_Test.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m )\n\u001b[1;32m--> 403\u001b[0m \u001b[43mresult_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_path)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:2439\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2428\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2429\u001b[0m     df,\n\u001b[0;32m   2430\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2437\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2438\u001b[0m )\n\u001b[1;32m-> 2439\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    941\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 943\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     59\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1243\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1244\u001b[0m )\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:\\\\Savidhu_OneDrive\\\\OneDrive - Hirdaramani Group\\\\Projects\\\\Cut to Ship Prediction Model\\\\Cut to Ship Report Automation\\\\Cut_to_Ship_Week_43_Test.xlsx'"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Cut to Ship Report Automation\n",
    "# Robust to column name variations\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions for cleaning and standardizing inputs\n",
    "# -----------------------------\n",
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalizing column names by removing extra whitespace and trimming edges.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)  # collapsing whitespace/newlines/tabs\n",
    "        .str.strip()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def find_col(df: pd.DataFrame, text: str, prefer_exact: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Identifying the correct column even if the column name slightly varies.\n",
    "    - Trying exact match first (case-insensitive)\n",
    "    - Otherwise selecting the first column that contains the keyword\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    if prefer_exact:\n",
    "        for c in cols:\n",
    "            if c.strip().lower() == text.strip().lower():\n",
    "                return c\n",
    "\n",
    "    matches = [c for c in cols if text.lower() in c.lower()]\n",
    "    if not matches:\n",
    "        raise KeyError(\n",
    "            f\"Could not find a column containing '{text}'. Available columns:\\n{cols}\"\n",
    "        )\n",
    "    return matches[0]\n",
    "\n",
    "def ensure_datetime(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converting values to datetime format safely (invalid values become NaT).\"\"\"\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def safe_str(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Converting to string while keeping missing values safe for concatenations.\"\"\"\n",
    "    return s.fillna(\"\").astype(str)\n",
    "\n",
    "# -----------------------------\n",
    "# Defining file paths for the 7 source reports\n",
    "# -----------------------------\n",
    "D1_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Style Closure -Week 43.xlsx\"\n",
    "D2_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Garment Sales Order-Week 43.xlsx\"\n",
    "D3_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Order Book -Week 43.xlsx\"\n",
    "D4_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Transaction Summary -Week 43.xlsx\"\n",
    "D5_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Export Summary -Week 43.xlsx\"\n",
    "D6_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Last Shipment- Week 43.xlsx\"\n",
    "D7_path = r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\\Master sheet - customer name.xlsx\"\n",
    "\n",
    "# -----------------------------\n",
    "# Loading all source datasets into pandas DataFrames\n",
    "# -----------------------------\n",
    "D1 = pd.read_excel(D1_path, sheet_name=\"Sheet1\")\n",
    "D2 = pd.read_excel(D2_path, sheet_name=\"Sheet1\")\n",
    "D3 = pd.read_excel(D3_path, sheet_name=\"Sheet1\")\n",
    "D4 = pd.read_excel(D4_path, sheet_name=\"Sheet1\")\n",
    "D5 = pd.read_excel(D5_path, sheet_name=\"Sheet1\")\n",
    "D6 = pd.read_excel(D6_path, sheet_name=\"Sheet1\")\n",
    "D7 = pd.read_excel(D7_path, sheet_name=\"Sheet1\")\n",
    "\n",
    "# Cleaning column headers to make matching reliable\n",
    "D1 = clean_cols(D1)\n",
    "D2 = clean_cols(D2)\n",
    "D3 = clean_cols(D3)\n",
    "D4 = clean_cols(D4)\n",
    "D5 = clean_cols(D5)\n",
    "D6 = clean_cols(D6)\n",
    "D7 = clean_cols(D7)\n",
    "\n",
    "# -----------------------------\n",
    "# Resolving the required column names dynamically (robust to naming variations)\n",
    "# -----------------------------\n",
    "# Resolving D2 filter columns\n",
    "D2_gen = find_col(D2, \"General sales order\")\n",
    "D2_sample = find_col(D2, \"Sample sales orders\")\n",
    "D2_salesman = find_col(D2, \"Salesman order\")\n",
    "D2_sales_order = find_col(D2, \"Sales order\")  # could be Sales order, Sales order.1, etc.\n",
    "\n",
    "# Resolving D1 columns\n",
    "D1_sales_order = find_col(D1, \"Sales order\")\n",
    "D1_customer = find_col(D1, \"Customer account\")\n",
    "D1_style_closed = find_col(D1, \"Style closed date\")\n",
    "\n",
    "# Resolving D7 columns\n",
    "D7_customer = find_col(D7, \"Customer\")\n",
    "D7_calling = find_col(D7, \"Calling Name\")\n",
    "\n",
    "# Resolving D3 columns\n",
    "D3_sales_order = find_col(D3, \"Sales order\")\n",
    "D3_division = find_col(D3, \"Division\")\n",
    "D3_season = find_col(D3, \"Season\")\n",
    "D3_style_no = find_col(D3, \"Style number\")\n",
    "D3_item_type = find_col(D3, \"Garment item type\")\n",
    "D3_site = find_col(D3, \"Site\")\n",
    "D3_set_garment = find_col(D3, \"Set garment\")\n",
    "D3_qty = find_col(D3, \"Quantity\")\n",
    "\n",
    "# Resolving D4 columns\n",
    "D4_sales_order = find_col(D4, \"Sales order\")\n",
    "D4_unit = find_col(D4, \"Unit\")\n",
    "D4_qty = find_col(D4, \"Qty\")\n",
    "\n",
    "# Resolving D5 columns\n",
    "D5_sales_order = find_col(D5, \"Sales order\")\n",
    "D5_site = find_col(D5, \"Site\")\n",
    "D5_invoice = find_col(D5, \"Customer invoice\")\n",
    "D5_date = find_col(D5, \"Date\")\n",
    "D5_invoice_qty = find_col(D5, \"Invoice qty\")\n",
    "D5_fob = find_col(D5, \"FOB\")\n",
    "\n",
    "# Resolving D6 columns\n",
    "D6_sales_order = find_col(D6, \"Sales order\")\n",
    "D6_approved_date = find_col(D6, \"Approved date\")\n",
    "\n",
    "# Converting date fields into datetime format\n",
    "D1[D1_style_closed] = ensure_datetime(D1[D1_style_closed])\n",
    "D6[D6_approved_date] = ensure_datetime(D6[D6_approved_date])\n",
    "D5[D5_date] = ensure_datetime(D5[D5_date])\n",
    "\n",
    "# -----------------------------\n",
    "# Filtering bulk sales orders from D2 (keeping only rows where all 3 flags are \"No\")\n",
    "# -----------------------------\n",
    "filtered_D2 = D2[\n",
    "    (D2[D2_gen] == \"No\") &\n",
    "    (D2[D2_sample] == \"No\") &\n",
    "    (D2[D2_salesman] == \"No\")\n",
    "][[D2_sales_order]].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Filtering D1 to keep only matching bulk sales orders (semi-join logic)\n",
    "# -----------------------------\n",
    "filtered_D1 = D1[D1[D1_sales_order].isin(filtered_D2[D2_sales_order])].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Initializing the result dataset using filtered Sales Orders\n",
    "# -----------------------------\n",
    "result = filtered_D1[[D1_sales_order]].copy()\n",
    "result = result.rename(columns={D1_sales_order: \"Sales_order\"})\n",
    "\n",
    "# -----------------------------\n",
    "# Adding Customer details from D1\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D1[[D1_sales_order, D1_customer]].rename(columns={D1_sales_order: \"Sales_order\", D1_customer: \"Customer\"}),\n",
    "    on=\"Sales_order\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Adding Calling Name from master mapping (D7) using Customer\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D7[[D7_customer, D7_calling]].rename(columns={D7_customer: \"Customer\", D7_calling: \"Calling_Name\"}),\n",
    "    on=\"Customer\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Adding order attributes from Order Book (D3) using Sales Order\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D3[[D3_sales_order, D3_division, D3_season, D3_style_no, D3_item_type, D3_site, D3_set_garment]].rename(\n",
    "        columns={\n",
    "            D3_sales_order: \"Sales_order\",\n",
    "            D3_division: \"Division\",\n",
    "            D3_season: \"Season\",\n",
    "            D3_style_no: \"Style_number\",\n",
    "            D3_item_type: \"Garment_item_type\",\n",
    "            D3_site: \"Unit\",\n",
    "            D3_set_garment: \"Set_garment\",\n",
    "        }\n",
    "    ),\n",
    "    on=\"Sales_order\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Adding \"Last Shipped\" date from D6 by taking the latest Approved date per Sales order\n",
    "# -----------------------------\n",
    "last_shipped = (\n",
    "    D6.groupby(D6_sales_order, as_index=False)[D6_approved_date]\n",
    "    .max()\n",
    "    .rename(columns={D6_sales_order: \"Sales_order\", D6_approved_date: \"Last_Shipped\"})\n",
    ")\n",
    "\n",
    "result = result.merge(last_shipped, on=\"Sales_order\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Adding \"Style closed date\" from D1\n",
    "# -----------------------------\n",
    "result = result.merge(\n",
    "    D1[[D1_sales_order, D1_style_closed]].rename(columns={D1_sales_order: \"Sales_order\", D1_style_closed: \"Style_closed_date\"}),\n",
    "    on=\"Sales_order\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Deriving Month and Week from Style closed date\n",
    "# -----------------------------\n",
    "result[\"Month\"] = result[\"Style_closed_date\"].dt.month_name().str[:3]\n",
    "\n",
    "iso_week = result[\"Style_closed_date\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "result[\"Week\"] = iso_week.apply(lambda x: f\"Week {int(x):02d}\" if pd.notna(x) else np.nan)\n",
    "\n",
    "# -----------------------------\n",
    "# Deriving Operation type based on Sales order prefix\n",
    "# -----------------------------\n",
    "so_str = safe_str(result[\"Sales_order\"])\n",
    "result[\"Operation\"] = np.where(\n",
    "    so_str.str.startswith(\"N\"), \"Knit Operation\",\n",
    "    np.where(so_str.str.startswith(\"W\"), \"Woven Operation\", \"Other Operation\")\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Removing excluded Customers from the dataset\n",
    "# -----------------------------\n",
    "result = result[~result[\"Customer\"].astype(str).str.lower().str.contains(\"oritapparels|southasiatextiles\", regex=True, na=False)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Creating a unique \"Code\" key by combining Sales order and Unit\n",
    "# -----------------------------\n",
    "result[\"Code\"] = safe_str(result[\"Sales_order\"]) + safe_str(result[\"Unit\"])\n",
    "\n",
    "D3[\"Code\"] = safe_str(D3[D3_sales_order]) + safe_str(D3[D3_site])\n",
    "D4[\"Code\"] = (safe_str(D4[D4_sales_order]) + safe_str(D4[D4_unit])).str.upper()\n",
    "D5[\"Code\"] = safe_str(D5[D5_sales_order]) + safe_str(D5[D5_site])\n",
    "\n",
    "# -----------------------------\n",
    "# Aggregating Order Qty, Cut Qty, and Ship Qty by Code\n",
    "# -----------------------------\n",
    "order_qty = (\n",
    "    D3[~D3[D3_site].astype(str).str.contains(\"HIKH-SAMP|HKSAM\", regex=True, na=False)]\n",
    "    .groupby(\"Code\", as_index=False)[D3_qty]\n",
    "    .sum()\n",
    "    .rename(columns={D3_qty: \"Order_Qty\"})\n",
    ")\n",
    "\n",
    "cut_qty = (\n",
    "    D4.groupby(\"Code\", as_index=False)[D4_qty]\n",
    "    .sum()\n",
    "    .rename(columns={D4_qty: \"Cut_Qty\"})\n",
    ")\n",
    "\n",
    "ship_qty = (\n",
    "    D5[\n",
    "        ~D5[D5_invoice].astype(str).str.lower().str.match(r\"^(scl|rtn|dummy|sms|ss)\", na=False)\n",
    "    ]\n",
    "    .drop_duplicates(subset=[D5_invoice, D5_date, D5_invoice_qty])\n",
    "    .groupby(\"Code\", as_index=False)[D5_invoice_qty]\n",
    "    .sum()\n",
    "    .rename(columns={D5_invoice_qty: \"Ship_Qty\"})\n",
    ")\n",
    "\n",
    "# Merging aggregated quantities into the result dataset\n",
    "result = result.merge(order_qty, on=\"Code\", how=\"left\")\n",
    "result = result.merge(cut_qty, on=\"Code\", how=\"left\")\n",
    "result = result.merge(ship_qty, on=\"Code\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Assigning Sales Order type\n",
    "# -----------------------------\n",
    "result[\"SO_Type\"] = \"Bulk\"\n",
    "\n",
    "# -----------------------------\n",
    "# Deriving Pcs and adjusting Cut Qty for pack styles\n",
    "# -----------------------------\n",
    "set_g = result[\"Set_garment\"].astype(str)\n",
    "style_num = result[\"Style_number\"].astype(str)\n",
    "\n",
    "pcs = np.where(\n",
    "    set_g.eq(\"Single\"), 1,\n",
    "    np.where(\n",
    "        set_g.str.contains(\"Pack\", na=False),\n",
    "        pd.to_numeric(style_num.str.extract(r\"(\\d+)(?=PK|P)\")[0], errors=\"coerce\"),\n",
    "        np.nan\n",
    "    )\n",
    ")\n",
    "\n",
    "result[\"Pcs\"] = pcs.astype(float)\n",
    "result.loc[result[\"Pcs\"] > 10, \"Pcs\"] = np.nan\n",
    "\n",
    "result[\"Cut_Qty\"] = pd.to_numeric(result[\"Cut_Qty\"], errors=\"coerce\")\n",
    "result.loc[result[\"Pcs\"].notna(), \"Cut_Qty\"] = result.loc[result[\"Pcs\"].notna(), \"Cut_Qty\"] / result.loc[result[\"Pcs\"].notna(), \"Pcs\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Removing duplicate Codes (keeping the first record per Code)\n",
    "# -----------------------------\n",
    "result = result.drop_duplicates(subset=[\"Code\"], keep=\"first\").copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Calculating Cut/Ship, Order/Ship, and Order/Cut ratios\n",
    "# -----------------------------\n",
    "result[\"Cut/Ship\"] = result[\"Ship_Qty\"] / result[\"Cut_Qty\"]\n",
    "result[\"Order/Ship\"] = result[\"Ship_Qty\"] / result[\"Order_Qty\"]\n",
    "result[\"Order/Cut\"] = result[\"Cut_Qty\"] / result[\"Order_Qty\"]\n",
    "\n",
    "# -----------------------------\n",
    "# Calculating FOB (sum of FOB * Invoice qty) by Code\n",
    "# -----------------------------\n",
    "D5_fob_total = pd.to_numeric(D5[D5_fob], errors=\"coerce\") * pd.to_numeric(D5[D5_invoice_qty], errors=\"coerce\")\n",
    "fob_data = (\n",
    "    D5.assign(FOB_Total=D5_fob_total)\n",
    "    .groupby(\"Code\", as_index=False)[\"FOB_Total\"]\n",
    "    .sum()\n",
    "    .rename(columns={\"FOB_Total\": \"FOB\"})\n",
    ")\n",
    "\n",
    "result = result.merge(fob_data, on=\"Code\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Preparing the final output structure and column naming\n",
    "# -----------------------------\n",
    "result_out = result.rename(columns={\n",
    "    \"Sales_order\": \"Sales order\",\n",
    "    \"Calling_Name\": \"Calling Name\",\n",
    "    \"Division\": \"Div\",\n",
    "    \"Style_number\": \"Style number\",\n",
    "    \"Garment_item_type\": \"Garment item type\",\n",
    "    \"Last_Shipped\": \"Last Shipped\",\n",
    "    \"Style_closed_date\": \"Style closed date\",\n",
    "    \"Order_Qty\": \"Order Qty\",\n",
    "    \"Cut_Qty\": \"Cut Qty\",\n",
    "    \"Ship_Qty\": \"Ship Qty\",\n",
    "    \"SO_Type\": \"SO Type\",\n",
    "    \"Set_garment\": \"Set garment\",\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Filtering output to only include Style closed date in 2024\n",
    "# -----------------------------\n",
    "result_out[\"Style closed date\"] = ensure_datetime(result_out[\"Style closed date\"])\n",
    "result_out = result_out[result_out[\"Style closed date\"].dt.year == 2024].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Filling missing Cut Qty values using Ship Qty where applicable\n",
    "# -----------------------------\n",
    "result_out[\"Cut Qty\"] = pd.to_numeric(result_out[\"Cut Qty\"], errors=\"coerce\")\n",
    "result_out[\"Ship Qty\"] = pd.to_numeric(result_out[\"Ship Qty\"], errors=\"coerce\")\n",
    "result_out.loc[result_out[\"Cut Qty\"].isna() & result_out[\"Ship Qty\"].notna(), \"Cut Qty\"] = result_out.loc[\n",
    "    result_out[\"Cut Qty\"].isna() & result_out[\"Ship Qty\"].notna(), \"Ship Qty\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Excluding Corporate and Sample units from the final output\n",
    "# -----------------------------\n",
    "result_out[\"Unit\"] = result_out[\"Unit\"].astype(str)\n",
    "result_out = result_out[~result_out[\"Unit\"].str.contains(\"Corporate|Sample\", regex=True, na=False)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Selecting and ordering final columns for export\n",
    "# -----------------------------\n",
    "final_cols = [\n",
    "    \"Sales order\",\n",
    "    \"Customer\",\n",
    "    \"Calling Name\",\n",
    "    \"Div\",\n",
    "    \"Season\",\n",
    "    \"Style number\",\n",
    "    \"Garment item type\",\n",
    "    \"Unit\",\n",
    "    \"Last Shipped\",\n",
    "    \"Style closed date\",\n",
    "    \"Month\",\n",
    "    \"Order Qty\",\n",
    "    \"Cut Qty\",\n",
    "    \"Ship Qty\",\n",
    "    \"Cut/Ship\",\n",
    "    \"Order/Ship\",\n",
    "    \"Order/Cut\",\n",
    "    \"SO Type\",\n",
    "    \"Week\",\n",
    "    \"Operation\",\n",
    "    \"Set garment\",\n",
    "    \"Pcs\",\n",
    "    \"Code\",\n",
    "    \"FOB\",\n",
    "]\n",
    "\n",
    "final_cols_existing = [c for c in final_cols if c in result_out.columns]\n",
    "result_out = result_out[final_cols_existing].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Writing the final Cut to Ship report output to Excel\n",
    "# -----------------------------\n",
    "output_path = (\n",
    "    r\"D:\\Savidhu_OneDrive\\OneDrive - Hirdaramani Group\\Projects\"\n",
    "    r\"\\Cut to Ship Prediction Model\\Cut to Ship Report Automation\"\n",
    "    r\"\\Cut_to_Ship_Week_43_Test.xlsx\"\n",
    ")\n",
    "\n",
    "result_out.to_excel(output_path, index=False)\n",
    "print(\"Saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29003b29-ca4b-41ab-8023-02808d559744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
